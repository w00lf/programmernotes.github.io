{"expireTime":9007200885669301000,"key":"transformer-remark-markdown-ast-077e1e243b208a8a743e45e9b906c8fc-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypants-","val":{"type":"root","children":[{"type":"heading","depth":2,"children":[{"type":"text","value":"TL:DR previous part","position":{"start":{"line":2,"column":4,"offset":4},"end":{"line":2,"column":23,"offset":23},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":23,"offset":23},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"I was approached by one of my clients with a work that required to parse almost 500 million European routes to see what routes can be traveled by land transport. After some research, i decided to use graphhopper server application and python celery library.","position":{"start":{"line":4,"column":1,"offset":25},"end":{"line":4,"column":258,"offset":282},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":25},"end":{"line":4,"column":258,"offset":282},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Data preparation","position":{"start":{"line":6,"column":4,"offset":287},"end":{"line":6,"column":20,"offset":303},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":284},"end":{"line":6,"column":20,"offset":303},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Graphhopper uses osm.pbf files as input files in order to correctly draw its maps and compute directions. These files can be downloaded from ","position":{"start":{"line":8,"column":1,"offset":305},"end":{"line":8,"column":142,"offset":446},"indent":[]}},{"type":"link","title":null,"url":"https://download.geofabrik.de/europe.html","children":[{"type":"text","value":"geofabrik","position":{"start":{"line":8,"column":143,"offset":447},"end":{"line":8,"column":152,"offset":456},"indent":[]}}],"position":{"start":{"line":8,"column":142,"offset":446},"end":{"line":8,"column":196,"offset":500},"indent":[]}},{"type":"text","value":" site and can be freely used. However, another issue occurred during the preparation step: file sizes. The latest Europe map weighs more than 22Gb and that’s the compressed file! Graphhopper will also extract and set up his own metadata which will require additional storage usage. Even more, the larger the osm file the more there requirements for the RAM. That’s a huge requirement for memory, so i decided to shrink this osm file as much as possible. I needed only the West Europe map without Eastern Europe, Scandinavia, and England.","position":{"start":{"line":8,"column":196,"offset":500},"end":{"line":8,"column":733,"offset":1037},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":305},"end":{"line":8,"column":733,"offset":1037},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Shrink OSM files","position":{"start":{"line":10,"column":4,"offset":1042},"end":{"line":10,"column":20,"offset":1058},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":1039},"end":{"line":10,"column":20,"offset":1058},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Fortunately, osm files can be easily manipulated and feated to your needs. There is a tool called ","position":{"start":{"line":12,"column":1,"offset":1060},"end":{"line":12,"column":99,"offset":1158},"indent":[]}},{"type":"linkReference","identifier":"osmosis","label":"osmosis","referenceType":"shortcut","children":[{"type":"text","value":"osmosis","position":{"start":{"line":12,"column":100,"offset":1159},"end":{"line":12,"column":107,"offset":1166},"indent":[]}}],"position":{"start":{"line":12,"column":99,"offset":1158},"end":{"line":12,"column":108,"offset":1167},"indent":[]}},{"type":"text","value":" (","position":{"start":{"line":12,"column":108,"offset":1167},"end":{"line":12,"column":110,"offset":1169},"indent":[]}},{"type":"link","title":null,"url":"https://wiki.openstreetmap.org/wiki/Osmosis","children":[{"type":"text","value":"https://wiki.openstreetmap.org/wiki/Osmosis","position":{"start":{"line":12,"column":110,"offset":1169},"end":{"line":12,"column":153,"offset":1212},"indent":[]}}],"position":{"start":{"line":12,"column":110,"offset":1169},"end":{"line":12,"column":153,"offset":1212},"indent":[]}},{"type":"text","value":") that can do that and much more. Here is an example of extracting a map of Germany with supplied polygon into a separate map file:","position":{"start":{"line":12,"column":153,"offset":1212},"end":{"line":12,"column":284,"offset":1343},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":1060},"end":{"line":12,"column":284,"offset":1343},"indent":[]}},{"type":"html","lang":"sh","meta":null,"value":"<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">$: osmosis --read-xml file=&quot;planet-latest.osm&quot; --bounding-polygon file=&quot;country2pts.txt&quot; --write-xml file=&quot;germany.osm&quot;</code></pre></div>","position":{"start":{"line":14,"column":1,"offset":1345},"end":{"line":16,"column":4,"offset":1474},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Where ","position":{"start":{"line":18,"column":1,"offset":1476},"end":{"line":18,"column":7,"offset":1482},"indent":[]}},{"type":"html","value":"<code class=\"language-text\">country2pts.txt</code>","position":{"start":{"line":18,"column":7,"offset":1482},"end":{"line":18,"column":24,"offset":1499},"indent":[]}},{"type":"text","value":" is a ","position":{"start":{"line":18,"column":24,"offset":1499},"end":{"line":18,"column":30,"offset":1505},"indent":[]}},{"type":"link","title":null,"url":"https://wiki.openstreetmap.org/wiki/Osmosis/Polygon_Filter_File_Format","children":[{"type":"text","value":"polygon filter file","position":{"start":{"line":18,"column":31,"offset":1506},"end":{"line":18,"column":50,"offset":1525},"indent":[]}}],"position":{"start":{"line":18,"column":30,"offset":1505},"end":{"line":18,"column":123,"offset":1598},"indent":[]}},{"type":"text","value":". In order to create such polygon one can use an online tool called ","position":{"start":{"line":18,"column":123,"offset":1598},"end":{"line":18,"column":191,"offset":1666},"indent":[]}},{"type":"link","title":null,"url":"https://export.hotosm.org/en/v3/exports/new/describe","children":[{"type":"text","value":"hotosm","position":{"start":{"line":18,"column":192,"offset":1667},"end":{"line":18,"column":198,"offset":1673},"indent":[]}}],"position":{"start":{"line":18,"column":191,"offset":1666},"end":{"line":18,"column":253,"offset":1728},"indent":[]}},{"type":"text","value":". The polygon file itself is just a collection of map points on each row that describes our polygon boundaries:","position":{"start":{"line":18,"column":253,"offset":1728},"end":{"line":18,"column":364,"offset":1839},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":1476},"end":{"line":18,"column":364,"offset":1839},"indent":[]}},{"type":"html","lang":"txt","meta":null,"value":"<div class=\"gatsby-highlight\" data-language=\"txt\"><pre class=\"language-txt\"><code class=\"language-txt\">australia_v\nfirst_area\n     0.1446693E+03    -0.3826255E+02\n     0.1446627E+03    -0.3825661E+02\n     0.1446763E+03    -0.3824465E+02\n     0.1446813E+03    -0.3824343E+02\n     0.1446824E+03    -0.3824484E+02\n     0.1446826E+03    -0.3825356E+02\n     0.1446876E+03    -0.3825210E+02\n     0.1446919E+03    -0.3824719E+02\n     0.1447006E+03    -0.3824723E+02\n     0.1447042E+03    -0.3825078E+02\n     0.1446758E+03    -0.3826229E+02\n     0.1446693E+03    -0.3826255E+02\nEND\nsecond_area\n     0.1422436E+03    -0.3839315E+02\n     0.1422496E+03    -0.3839070E+02\n     0.1422543E+03    -0.3839025E+02\n     0.1422574E+03    -0.3839155E+02\n     0.1422467E+03    -0.3840065E+02\n     0.1422433E+03    -0.3840048E+02\n     0.1422420E+03    -0.3839857E+02\n     0.1422436E+03    -0.3839315E+02\nEND\nEND</code></pre></div>","position":{"start":{"line":20,"column":1,"offset":1841},"end":{"line":47,"column":4,"offset":2638},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Using hotosm i created ","position":{"start":{"line":49,"column":1,"offset":2640},"end":{"line":49,"column":24,"offset":2663},"indent":[]}},{"type":"html","value":"<code class=\"language-text\">.geojson</code>","position":{"start":{"line":49,"column":24,"offset":2663},"end":{"line":49,"column":34,"offset":2673},"indent":[]}},{"type":"text","value":" file and used its boundaries to create such polygon filter file. After that i only needed to extract land routes in the creared custom polygon:","position":{"start":{"line":49,"column":34,"offset":2673},"end":{"line":49,"column":178,"offset":2817},"indent":[]}}],"position":{"start":{"line":49,"column":1,"offset":2640},"end":{"line":49,"column":178,"offset":2817},"indent":[]}},{"type":"html","lang":"sh","meta":null,"value":"<div class=\"gatsby-highlight\" data-language=\"sh\"><pre class=\"language-sh\"><code class=\"language-sh\">$: osmosis \\\n  --read-xml europe-latest.osm \\\n  --way-key-value keyValueList=&quot;railway.tram,railway.tram_stop&quot; \\\n  --bounding-polygon file=&quot;created_polygon_filter_file_.txt&quot;\n  --used-node \\\n  --write-xml city_tram.osm</code></pre></div>","position":{"start":{"line":51,"column":1,"offset":2819},"end":{"line":58,"column":4,"offset":3045},"indent":[1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Because in this task i had only a list of cities to create routes permutations with i also needed to determine the exact coordinates for each city. As now i had our custom Europe polygon i used ","position":{"start":{"line":60,"column":1,"offset":3047},"end":{"line":60,"column":195,"offset":3241},"indent":[]}},{"type":"link","title":null,"url":"https://pypi.org/project/Shapely/","children":[{"type":"text","value":"shapely","position":{"start":{"line":60,"column":196,"offset":3242},"end":{"line":60,"column":203,"offset":3249},"indent":[]}}],"position":{"start":{"line":60,"column":195,"offset":3241},"end":{"line":60,"column":239,"offset":3285},"indent":[]}},{"type":"text","value":" in order to check how properly the coordinates were detected:","position":{"start":{"line":60,"column":239,"offset":3285},"end":{"line":60,"column":301,"offset":3347},"indent":[]}}],"position":{"start":{"line":60,"column":1,"offset":3047},"end":{"line":60,"column":301,"offset":3347},"indent":[]}},{"type":"html","lang":"python","meta":null,"value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> shapely<span class=\"token punctuation\">.</span>geometry\n<span class=\"token keyword\">import</span> shapely<span class=\"token punctuation\">.</span>geometry<span class=\"token punctuation\">.</span>polygon\n\n<span class=\"token comment\"># Points from our custom polygon</span>\ncoords <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n  <span class=\"token punctuation\">(</span><span class=\"token number\">81.434750</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">5.863332</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">(</span><span class=\"token number\">74.786230</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">6.704456</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">(</span><span class=\"token number\">62.807440</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">34.492960</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n  <span class=\"token punctuation\">(</span><span class=\"token number\">81.434750</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">5.863332</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span>\nCUSTOM_EUROPE_POLYGON <span class=\"token operator\">=</span> shapely<span class=\"token punctuation\">.</span>geometry<span class=\"token punctuation\">.</span>polygon<span class=\"token punctuation\">.</span>Polygon<span class=\"token punctuation\">(</span>coords<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> input_file<span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">for</span> coordinates <span class=\"token keyword\">in</span> csv<span class=\"token punctuation\">.</span>DictReader<span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> CUSTOM_EUROPE_POLYGON<span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span>shapely<span class=\"token punctuation\">.</span>geometry<span class=\"token punctuation\">.</span>Point<span class=\"token punctuation\">(</span>coordinates<span class=\"token punctuation\">[</span><span class=\"token string\">'lat'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> coordinates<span class=\"token punctuation\">[</span><span class=\"token string\">'lng'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Skipped: {}, not in europe poly'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>term<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">continue</span></code></pre></div>","position":{"start":{"line":62,"column":1,"offset":3349},"end":{"line":81,"column":4,"offset":3913},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"I now had an osm file which weighted in 12 Gb and that was an uncompressed osm file. The next step was the server setup.","position":{"start":{"line":83,"column":1,"offset":3915},"end":{"line":83,"column":121,"offset":4035},"indent":[]}}],"position":{"start":{"line":83,"column":1,"offset":3915},"end":{"line":83,"column":121,"offset":4035},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Server setup","position":{"start":{"line":85,"column":4,"offset":4040},"end":{"line":85,"column":16,"offset":4052},"indent":[]}}],"position":{"start":{"line":85,"column":1,"offset":4037},"end":{"line":85,"column":16,"offset":4052},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"The result osm file weighted 12 Gb uncompressed, graphhopper will unwind it and add an additional 12 Gb for its metadata, i also needed a good amount of memory in order to comfortably work with routes. The list itself had almost 500 million routes to parse, so I could not parse it in one go, so i really needed to track what routes were processed and what not. In order to do that i decided to use redis server, its simple, reliable and very fast, also it can be used with python celery library which i decided to also use in my setup. After some considerations i decided to use ","position":{"start":{"line":87,"column":1,"offset":4054},"end":{"line":87,"column":581,"offset":4634},"indent":[]}},{"type":"link","title":null,"url":"https://www.hetzner.com/","children":[{"type":"text","value":"hetzner","position":{"start":{"line":87,"column":582,"offset":4635},"end":{"line":87,"column":589,"offset":4642},"indent":[]}}],"position":{"start":{"line":87,"column":581,"offset":4634},"end":{"line":87,"column":616,"offset":4669},"indent":[]}},{"type":"text","value":" EX42 type box.","position":{"start":{"line":87,"column":616,"offset":4669},"end":{"line":87,"column":631,"offset":4684},"indent":[]}}],"position":{"start":{"line":87,"column":1,"offset":4054},"end":{"line":87,"column":631,"offset":4684},"indent":[]}},{"type":"paragraph","children":[{"type":"html","title":null,"url":"./hetzner.png","alt":"Hetzner","position":{"start":{"line":89,"column":1,"offset":4686},"end":{"line":89,"column":26,"offset":4711},"indent":[]},"value":"<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4594e84787caf247434d027521392f5f/1cc3c/hetzner.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 39.87341772151899%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABqklEQVQoz1WQzW/TQBDF/WcDEiSOaIKaOwUhwYFKiAMfBy4gDiAiJTJJKgW7IkG0om1KI+HYThx/rb0/Zh1K4ElvZ3d2dua9tabvPjB5+Ybxsxd4wzHT2QzPdfE8D+/4GHcyYfKxhzs+wvnsMBgM6PV6DIdD+v0+juPUcTQaMZFa69GTx9y91+HWndvYLZtut0uj0aDZbNaxYaJts9/dp723R6vVqmlLzrabNVuy77TbHBzcxwqDgGAZkGw2ZGmGUoqyqiiKgrIs0VrXTJKEOJaaLJM7tb0DKllyBaoCSWP5vk8URRhkec6P0xMuz89ZrWMKOV9jtVqxXC5Zr9dsZLhSJZQ+STjj65dPpOE3dOFjGUUGRkWtLE9RefKnjaaSnOH/0Ft1i6eo7zeIph3Kk5uoq+dYgViez+fEMtXYDMNI9glBsCRN078NjQvjJo7j7beUCjMmk8UPFZkIVjLFMhYMDQop/Hlxxq+rS0ptVO+Umeam2UZoBteIR+SLV5y5hxSL1+j10c7ytZJKPlvJg0rv7Bpq/Y9hk5Nz5b+luHhAdHqImj9E+e/5DeuwRTKf7Vl7AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Hetzner\"\n        title=\"Hetzner\"\n        src=\"/static/4594e84787caf247434d027521392f5f/f058b/hetzner.png\"\n        srcset=\"/static/4594e84787caf247434d027521392f5f/c26ae/hetzner.png 158w,\n/static/4594e84787caf247434d027521392f5f/6bdcf/hetzner.png 315w,\n/static/4594e84787caf247434d027521392f5f/f058b/hetzner.png 630w,\n/static/4594e84787caf247434d027521392f5f/40601/hetzner.png 945w,\n/static/4594e84787caf247434d027521392f5f/78612/hetzner.png 1260w,\n/static/4594e84787caf247434d027521392f5f/1cc3c/hetzner.png 2322w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>"}],"position":{"start":{"line":89,"column":1,"offset":4686},"end":{"line":89,"column":26,"offset":4711},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Workers","position":{"start":{"line":91,"column":4,"offset":4716},"end":{"line":91,"column":11,"offset":4723},"indent":[]}}],"position":{"start":{"line":91,"column":1,"offset":4713},"end":{"line":91,"column":11,"offset":4723},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"I decided to use celery and redis as transport. The script will read each term and start to combine it in a loop with other terms until ","position":{"start":{"line":93,"column":1,"offset":4725},"end":{"line":93,"column":137,"offset":4861},"indent":[]}},{"type":"html","value":"<code class=\"language-text\">CONCURENCY</code>","position":{"start":{"line":93,"column":137,"offset":4861},"end":{"line":93,"column":149,"offset":4873},"indent":[]}},{"type":"text","value":" number of routes is collected, then it will pass them to the celery worker group and wait for the processing to complete after that receive the results from celery and write them down. I also decided that it need a config option to start from a given point in the file, so i have introduced ","position":{"start":{"line":93,"column":149,"offset":4873},"end":{"line":93,"column":441,"offset":5165},"indent":[]}},{"type":"html","value":"<code class=\"language-text\">START_POINT</code>","position":{"start":{"line":93,"column":441,"offset":5165},"end":{"line":93,"column":454,"offset":5178},"indent":[]}},{"type":"text","value":" config env variable.","position":{"start":{"line":93,"column":454,"offset":5178},"end":{"line":93,"column":475,"offset":5199},"indent":[]}}],"position":{"start":{"line":93,"column":1,"offset":4725},"end":{"line":93,"column":475,"offset":5199},"indent":[]}},{"type":"html","lang":"python","meta":null,"value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> requests\n<span class=\"token keyword\">import</span> csv\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> itertools\n<span class=\"token keyword\">import</span> concurrent<span class=\"token punctuation\">.</span>futures\n<span class=\"token keyword\">import</span> router<span class=\"token punctuation\">.</span>redis_client\n<span class=\"token keyword\">import</span> celery\n<span class=\"token keyword\">import</span> hashlib\n<span class=\"token keyword\">from</span> router<span class=\"token punctuation\">.</span>tasks <span class=\"token keyword\">import</span> lookup_directions\n<span class=\"token keyword\">import</span> router<span class=\"token punctuation\">.</span>hasher\n\nSTART_POINT <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'START_POINT'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">or</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\nCONCURENCY <span class=\"token operator\">=</span> <span class=\"token number\">500</span>\nMAX_RESULT_BATCH <span class=\"token operator\">=</span> 10_000\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">flush_batch_main</span><span class=\"token punctuation\">(</span>batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  execution_result <span class=\"token operator\">=</span> celery<span class=\"token punctuation\">.</span>group<span class=\"token punctuation\">(</span>lookup_directions<span class=\"token punctuation\">.</span>s<span class=\"token punctuation\">(</span>\n      row<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> row<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> execution_result<span class=\"token punctuation\">]</span></code></pre></div>","position":{"start":{"line":95,"column":1,"offset":5201},"end":{"line":115,"column":4,"offset":5677},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"html","value":"<code class=\"language-text\">lookup_directions</code>","position":{"start":{"line":117,"column":1,"offset":5679},"end":{"line":117,"column":20,"offset":5698},"indent":[]}},{"type":"text","value":" is our celery task and is pretty straightforward:","position":{"start":{"line":117,"column":20,"offset":5698},"end":{"line":117,"column":70,"offset":5748},"indent":[]}}],"position":{"start":{"line":117,"column":1,"offset":5679},"end":{"line":117,"column":70,"offset":5748},"indent":[]}},{"type":"html","lang":"python","meta":null,"value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> absolute_import<span class=\"token punctuation\">,</span> unicode_literals\n<span class=\"token keyword\">from</span> celery <span class=\"token keyword\">import</span> Celery\n\n<span class=\"token comment\"># Use redis as broker</span>\napp <span class=\"token operator\">=</span> Celery<span class=\"token punctuation\">(</span><span class=\"token string\">'router'</span><span class=\"token punctuation\">,</span>\n             broker<span class=\"token operator\">=</span><span class=\"token string\">'redis://'</span><span class=\"token punctuation\">,</span>\n             backend<span class=\"token operator\">=</span><span class=\"token string\">'redis://'</span><span class=\"token punctuation\">,</span>\n             include<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'router.tasks'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nGRAPH_HOPPER_URL <span class=\"token operator\">=</span> <span class=\"token string\">'http://localhost:8989/route?point={}&amp;point={}&amp;type=json&amp;locale=en-US&amp;vehicle=car&amp;weighting=fastest&amp;elevation=false&amp;key='</span>\n\n<span class=\"token comment\"># Reuse request socket and config between the requests, increases the performance</span>\nrequests_session <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token decorator annotation punctuation\">@app<span class=\"token punctuation\">.</span>task</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">lookup_directions</span><span class=\"token punctuation\">(</span>start_point<span class=\"token punctuation\">,</span> end_point<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  path <span class=\"token operator\">=</span> <span class=\"token string\">'{} {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>start_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    result <span class=\"token operator\">=</span> requests_session<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>GRAPH_HOPPER_URL<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>\n        start_point<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>json<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> result<span class=\"token punctuation\">[</span><span class=\"token string\">'paths'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">and</span> result<span class=\"token punctuation\">[</span><span class=\"token string\">'paths'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n      first_path <span class=\"token operator\">=</span> result<span class=\"token punctuation\">[</span><span class=\"token string\">'paths'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n      <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token string\">'merged_term'</span><span class=\"token punctuation\">:</span> path<span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'term_start'</span><span class=\"token punctuation\">:</span> start_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'term_end'</span><span class=\"token punctuation\">:</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'coordinates_start'</span><span class=\"token punctuation\">:</span> start_point<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'coordinates_end'</span><span class=\"token punctuation\">:</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'distance'</span><span class=\"token punctuation\">:</span> first_path<span class=\"token punctuation\">[</span><span class=\"token string\">'distance'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'time'</span><span class=\"token punctuation\">:</span> first_path<span class=\"token punctuation\">[</span><span class=\"token string\">'time'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">'hops'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>first_path<span class=\"token punctuation\">[</span><span class=\"token string\">'instructions'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> identifier<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Skipped, error: {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>identifier<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">'merged_term'</span><span class=\"token punctuation\">:</span> path<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'term_start'</span><span class=\"token punctuation\">:</span> start_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'term_end'</span><span class=\"token punctuation\">:</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'coordinates_start'</span><span class=\"token punctuation\">:</span> start_point<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'coordinates_end'</span><span class=\"token punctuation\">:</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'distance'</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'time'</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'hops'</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">None</span>\n    <span class=\"token punctuation\">}</span></code></pre></div>","position":{"start":{"line":119,"column":1,"offset":5750},"end":{"line":164,"column":4,"offset":7282},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"The format of graphhopper api can be looked ","position":{"start":{"line":166,"column":1,"offset":7284},"end":{"line":166,"column":45,"offset":7328},"indent":[]}},{"type":"link","title":null,"url":"https://github.com/graphhopper/graphhopper/blob/master/docs/web/api-doc.md","children":[{"type":"text","value":"here","position":{"start":{"line":166,"column":46,"offset":7329},"end":{"line":166,"column":50,"offset":7333},"indent":[]}}],"position":{"start":{"line":166,"column":45,"offset":7328},"end":{"line":166,"column":127,"offset":7410},"indent":[]}},{"type":"text","value":".\nThe main script looked like this:","position":{"start":{"line":166,"column":127,"offset":7410},"end":{"line":167,"column":34,"offset":7445},"indent":[1]}}],"position":{"start":{"line":166,"column":1,"offset":7284},"end":{"line":167,"column":34,"offset":7445},"indent":[1]}},{"type":"html","lang":"python","meta":null,"value":"<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">,</span> result_file<span class=\"token punctuation\">,</span> flush_batch<span class=\"token punctuation\">,</span> hasher<span class=\"token punctuation\">,</span> concurency<span class=\"token punctuation\">,</span> max_result_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  writer <span class=\"token operator\">=</span> csv<span class=\"token punctuation\">.</span>DictWriter<span class=\"token punctuation\">(</span>result_file<span class=\"token punctuation\">,</span> fieldnames<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'merged_term'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'term_start'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'term_end'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'coordinates_start'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'coordinates_end'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'distance'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'time'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hops'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> quoting<span class=\"token operator\">=</span>csv<span class=\"token punctuation\">.</span>QUOTE_ALL<span class=\"token punctuation\">)</span>\n  writer<span class=\"token punctuation\">.</span>writeheader<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n  terms <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>csv<span class=\"token punctuation\">.</span>reader<span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  row_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n  result_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n  i <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n  <span class=\"token keyword\">for</span> row_1 <span class=\"token keyword\">in</span> terms<span class=\"token punctuation\">[</span>START_POINT<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> row_2 <span class=\"token keyword\">in</span> terms<span class=\"token punctuation\">:</span>\n      <span class=\"token comment\"># Track the current permutation number</span>\n      <span class=\"token keyword\">if</span> i <span class=\"token operator\">%</span> <span class=\"token number\">1000</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n      i <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n      sorted_points <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>row_1<span class=\"token punctuation\">,</span>row_2<span class=\"token punctuation\">]</span>\n      sorted_points<span class=\"token punctuation\">.</span>sort<span class=\"token punctuation\">(</span>key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n      start_point <span class=\"token operator\">=</span> sorted_points<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n      end_point <span class=\"token operator\">=</span> sorted_points<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n      path <span class=\"token operator\">=</span> <span class=\"token string\">'{} {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>start_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n      <span class=\"token keyword\">if</span> start_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> end_point<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">or</span> route_exists<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Skipped, already exists: {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">continue</span>\n\n      row_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>start_point<span class=\"token punctuation\">,</span> end_point<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n      <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>row_batch<span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> concurency<span class=\"token punctuation\">:</span>\n        row_batch<span class=\"token punctuation\">,</span> execution_result <span class=\"token operator\">=</span> flush_batch<span class=\"token punctuation\">(</span>row_batch<span class=\"token punctuation\">)</span>\n        result_batch<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>execution_result<span class=\"token punctuation\">)</span>\n\n      <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>result_batch<span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> max_result_batch<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Flushed'</span><span class=\"token punctuation\">)</span>\n        writer<span class=\"token punctuation\">.</span>writerows<span class=\"token punctuation\">(</span>result_batch<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> entry <span class=\"token keyword\">in</span> result_batch<span class=\"token punctuation\">:</span>\n          memorize_route<span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">[</span><span class=\"token string\">'merged_term'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        result_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n  <span class=\"token keyword\">if</span> row_batch<span class=\"token punctuation\">:</span>\n    row_batch<span class=\"token punctuation\">,</span> execution_result <span class=\"token operator\">=</span> flush_batch<span class=\"token punctuation\">(</span>row_batch<span class=\"token punctuation\">)</span>\n    result_batch<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>execution_result<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">if</span> result_batch<span class=\"token punctuation\">:</span>\n    writer<span class=\"token punctuation\">.</span>writerows<span class=\"token punctuation\">(</span>result_batch<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> entry <span class=\"token keyword\">in</span> result_batch<span class=\"token punctuation\">:</span>\n      memorize_route<span class=\"token punctuation\">(</span>entry<span class=\"token punctuation\">[</span><span class=\"token string\">'merged_term'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'INPUT'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> input_file<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'RESULT'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a+'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> result_file<span class=\"token punctuation\">:</span>\n      main<span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">,</span> result_file<span class=\"token punctuation\">,</span> flush_batch_main<span class=\"token punctuation\">,</span>\n           router<span class=\"token punctuation\">.</span>hasher<span class=\"token punctuation\">,</span> CONCURENCY<span class=\"token punctuation\">,</span> MAX_RESULT_BATCH<span class=\"token punctuation\">)</span></code></pre></div>","position":{"start":{"line":169,"column":1,"offset":7447},"end":{"line":222,"column":4,"offset":9273},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"html","value":"<code class=\"language-text\">memorize_route</code>","position":{"start":{"line":224,"column":1,"offset":9275},"end":{"line":224,"column":17,"offset":9291},"indent":[]}},{"type":"text","value":" and ","position":{"start":{"line":224,"column":17,"offset":9291},"end":{"line":224,"column":22,"offset":9296},"indent":[]}},{"type":"html","value":"<code class=\"language-text\">route_exists</code>","position":{"start":{"line":224,"column":22,"offset":9296},"end":{"line":224,"column":36,"offset":9310},"indent":[]}},{"type":"text","value":" is just a wrapper for redis client that checked redis key for existence and write one after we process it. Everything was in place and i was ready to start the processing. However, new challenges awaited me ahead. Stay tuned for the final article!","position":{"start":{"line":224,"column":36,"offset":9310},"end":{"line":224,"column":284,"offset":9558},"indent":[]}}],"position":{"start":{"line":224,"column":1,"offset":9275},"end":{"line":224,"column":284,"offset":9558},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":224,"column":284,"offset":9558}}}}